{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.optim.lr_scheduler as scheduler\n",
    "from torch.utils.data import random_split,DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10,CIFAR100\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor,Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "0\n",
      "1\n",
      "GeForce RTX 3090\n",
      "<torch.cuda.device object at 0x000001ABD3658E48>\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "학습을 진행하는 기기: cuda:0\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "print('학습을 진행하는 기기:',device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds10=CIFAR10(root=\"./data\",download=True,train=True,transform=transform)\n",
    "ts10=CIFAR10(root=\"./data\",download=True,train=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr10,vs10,_=random_split(ds10,[10000,10000,30000],torch.manual_seed(1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class_count={}\n",
    "for i in tr10:\n",
    "    if i[1] not in class_count:\n",
    "        class_count[i[1]]=0\n",
    "    class_count[i[1]]+=1\n",
    "print(class_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10),\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        #out = out.view(out.size(0),-1) #Flatten feature mapes to one-dimension vector\n",
    "        out = out.view(-1,16*5*5)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "    def myForward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCnn=MyCNN().to(device)\n",
    "training_epochs=20\n",
    "batch_size=4\n",
    "obj=nn.CrossEntropyLoss().to(device)\n",
    "opt=SGD(myCnn.parameters(),lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sch=scheduler.StepLR(optimizer=opt,step_size=40,gamma=0.1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr10_loader=DataLoader(dataset=tr10,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "vs10_loader=DataLoader(dataset=vs10,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCnn=MyCNN().to(device)\n",
    "training_epochs=8\n",
    "batch_size=4\n",
    "obj=nn.CrossEntropyLoss().to(device)\n",
    "opt=SGD(myCnn.parameters(),lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time : 62.079036712646484\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    training_loss=0.0\n",
    "    validation_loss=0.0\n",
    "    for X,y in tr10_loader:\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        output=myCnn(X) \n",
    "        cost=obj(output,y)\n",
    "        cost.backward()\n",
    "        opt.step()\n",
    "        \n",
    "print(\"Time :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr10_loader_1=DataLoader(dataset=tr10,\n",
    "                      batch_size=1,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tr_set=[]\n",
    "label_tr_set=[]\n",
    "for image, label in tr10_loader_1:\n",
    "    #print(image.shape)\n",
    "    image_tr_set.append(myCnn.myForward(image.to(device)).to('cpu').detach().numpy().reshape(400,))\n",
    "    label_tr_set.append(int(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF=RandomForestClassifier()\n",
    "RF.fit(image_tr_set,label_tr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts10_loader_1=DataLoader(dataset=ts10,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ts_set=[]\n",
    "label_ts_set=[]\n",
    "for image, label in ts10_loader_1:\n",
    "    #print(image.shape)\n",
    "    image_ts_set.append(myCnn.myForward(image.to(device)).to('cpu').detach().numpy().reshape(400,))\n",
    "    label_ts_set.append(int(label[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 49.05\n"
     ]
    }
   ],
   "source": [
    "pred=RF.predict(image_ts_set)\n",
    "correct=0\n",
    "for i in range(len(label_ts_set)):\n",
    "    if pred[i]==label_ts_set[i]:\n",
    "        correct+=1\n",
    "print(\"Accuracy :\",correct*100/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "ds100=CIFAR100(root=\"./data\",download=True,train=True,transform=transform)\n",
    "ts100=CIFAR100(root=\"./data\",download=True,train=False,transform=transform)\n",
    "tr100,vs100,_=random_split(ds100,[10000,10000,30000],torch.manual_seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr100_loader=DataLoader(dataset=tr100,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      drop_last=True)\n",
    "\n",
    "vs100_loader=DataLoader(dataset=vs100,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5,stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,100),\n",
    "            )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        #out = out.view(out.size(0),-1) #Flatten feature mapes to one-dimension vector\n",
    "        out = out.view(-1,16*5*5)\n",
    "        out = self.layer3(out)\n",
    "        return out\n",
    "    \n",
    "    def myForward(self,x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x.view(-1,16*5*5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCnn=MyCNN().to(device)\n",
    "training_epochs=11\n",
    "batch_size=4\n",
    "obj=nn.CrossEntropyLoss().to(device)\n",
    "opt=SGD(myCnn.parameters(),lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time : 83.88899755477905\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    training_loss=0.0\n",
    "    validation_loss=0.0\n",
    "    for X,y in tr100_loader:\n",
    "        X=X.to(device)\n",
    "        y=y.to(device)\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        output=myCnn(X) \n",
    "        cost=obj(output,y)\n",
    "        cost.backward()\n",
    "        opt.step()\n",
    "        \n",
    "print(\"Time :\",time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr100_loader_1=DataLoader(dataset=tr100,\n",
    "                      batch_size=1,\n",
    "                      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "image100_tr_set=[]\n",
    "label100_tr_set=[]\n",
    "for image, label in tr100_loader_1:\n",
    "    #print(image.shape)\n",
    "    image100_tr_set.append(myCnn.myForward(image.to(device)).to('cpu').detach().numpy().reshape(400,))\n",
    "    label100_tr_set.append(int(label[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF100=RandomForestClassifier()\n",
    "RF100.fit(image100_tr_set,label100_tr_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts100_loader_1=DataLoader(dataset=ts100,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image100_ts_set=[]\n",
    "label100_ts_set=[]\n",
    "for image, label in ts100_loader_1:\n",
    "    #print(image.shape)\n",
    "    image100_ts_set.append(myCnn.myForward(image.to(device)).to('cpu').detach().numpy().reshape(400,))\n",
    "    label100_ts_set.append(int(label[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 19.13\n"
     ]
    }
   ],
   "source": [
    "pred=RF100.predict(image100_ts_set)\n",
    "correct=0\n",
    "for i in range(len(label100_ts_set)):\n",
    "    if pred[i]==label100_ts_set[i]:\n",
    "        correct+=1\n",
    "print(\"Accuracy :\",correct*100/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
